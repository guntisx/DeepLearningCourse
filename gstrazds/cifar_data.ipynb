{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in this notebook is based on <https://github.com/MBMS80/Writing-Cifar10-dataset-to-image-files-as-.tif-or-.jpg->  \n",
    "( original author:\n",
    "[Mehdi Maboudi](https://www.tu-braunschweig.de/igp/mitarbeiter/maboudi/), September 2019,\n",
    " Technical University of Braunschweig )\n",
    " \n",
    "Implements:\n",
    "- Writing Cifar10 dataset to image files as '.tif' or '.jpg'  \n",
    "- Reading image files into numpy arrays compatible with the standard Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio\n",
    "import imageio #Python library for reading and writing image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='iso-8859-1')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "import torchvision\n",
    "\n",
    "cifar10 = torchvision.datasets.CIFAR10('./data', train=True, download=True)\n",
    "cifar10_val = torchvision.datasets.CIFAR10('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60000 32x32 colour images in 10 classes, with 6000 images per class.  \n",
    "There are 50000 training images and 10000 test images.  \n",
    "***\n",
    "__png__ images of CIFAR-10 will be saved in 10 subdirectories of each label under the __test__ and __train__ directories as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load cifar10 from local files\n",
    "DATA_DIR   = './data/'\n",
    "CIFAR10_DIR   = DATA_DIR + 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_pickle_files = sorted(glob.glob(CIFAR10_DIR + 'data_batch_*'))\n",
    "test_batch_pickle_file = CIFAR10_DIR + 'test_batch'\n",
    "meta_data_pickle_file  = CIFAR10_DIR + 'batches.meta'\n",
    "\n",
    "print(training_batch_pickle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = unpickle(meta_data_pickle_file)\n",
    "# print(meta_data)\n",
    "# {'num_cases_per_batch': 10000,\n",
    "# 'label_names': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],\n",
    "# 'num_vis': 3072}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = ['airplane',\n",
    "# 'automobile',\n",
    "# 'bird',\n",
    "# 'cat',\n",
    "# 'deer',\n",
    "# 'dog',\n",
    "# 'frog',\n",
    "# 'horse',\n",
    "# 'ship',\n",
    "# 'truck']\n",
    "# nb_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = meta_data['label_names']\n",
    "nb_classes = len(class_names)\n",
    "print(nb_classes, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data = []\n",
    "for pickle_file in training_batch_pickle_files:\n",
    "    data_dict = unpickle(pickle_file)\n",
    "    print(f\"{data_dict['batch_label']}: len={len(data_dict['labels'])} {data_dict.keys()}\")\n",
    "    assert(len(data_dict['labels']) == len(data_dict['data']))\n",
    "    assert(len(data_dict['labels']) == len(data_dict['filenames']))\n",
    "    cifar_data.append(data_dict)\n",
    "    \n",
    "print()\n",
    "test_batch = unpickle(test_batch_pickle_file)\n",
    "print(f\"{test_batch['batch_label']}: len={len(test_batch['labels'])} {test_batch.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict['batch_label'], len(data_dict['filenames']), data_dict['filenames'][0:5])\n",
    "cifar10_batch5 = cifar_data[4]['data'] \n",
    "print(\"dtype:\", cifar10_batch5.dtype, \"shape:\", cifar10_batch5.shape)\n",
    "print(cifar10_batch5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# a = []\n",
    "# for i in range(0,5):\n",
    "#     r = [i*5+c for c in range(0,5)]\n",
    "#     a.append(r)\n",
    "# a = np.array(a)\n",
    "# print(\"a=\",a)\n",
    "# print(a.shape)\n",
    "# print()\n",
    "# a2 = np.stack((a, 100+a, 200+a))\n",
    "# print(a2.shape)\n",
    "# b2 = np.stack((a2, 1000+a2))\n",
    "# print(b2.shape)\n",
    "# print(b2)\n",
    "# c2 = np.reshape(b2, (2, 3, 25))\n",
    "# print()\n",
    "# print(c2.shape)\n",
    "# print(c2)\n",
    "# print()\n",
    "# c2 = np.transpose(c2, axes=(0,2,1))\n",
    "# print(c2.shape)\n",
    "# print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_cifar_img_data(imgdata_batch):\n",
    "    reshaped = np.reshape(imgdata_batch, (imgdata_batch.shape[0], 3, 32, 32))\n",
    "    # print(reshaped.shape, end=' ')\n",
    "    reshaped = np.transpose(reshaped, axes=(0,2,3,1))\n",
    "    # print(\"->\", reshaped.shape)\n",
    "    return reshaped\n",
    "\n",
    "def reshape_cifar_img(imgdata):\n",
    "    reshaped = np.reshape(imgdata, (3, 32, 32))\n",
    "    # print(reshaped.shape, end=' ')\n",
    "    reshaped = np.transpose(reshaped, axes=(1,2,0))\n",
    "    # print(\"->\", reshaped.shape)\n",
    "    return reshaped\n",
    "\n",
    "# def reshape_imgdata(imgdata, flatten=0):\n",
    "#     assert len(imgdata.shape) == 3, imgdata.shape # (Width, Height, Channels=3)\n",
    "#     reshaped = np.transpose(imgdata,axes=(2,0,1))\n",
    "#     if flatten == 1:\n",
    "#         outshape = (imgdata.shape[2]*imgdata.shape[0]*imgdata.shape[1],) # completely flatten to 1D\n",
    "#     elif flatten == 2:\n",
    "#         outshape = (imgdata.shape[2],imgdata.shape[0]*imgdata.shape[1]) # C=3 channels, W x H values \n",
    "#     elif flatten:\n",
    "#         assert False, f\"Unsupported arg: flatten={flatten}\"\n",
    "#         flatten = 0\n",
    "#     if flatten:\n",
    "#         reshaped = np.reshape(reshaped,outshape)\n",
    "#     return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE IMAGES\n",
    "\n",
    "def plotImages_categories( images, labels, n_rows=5, n_cols=4, figsize=(10, 10)):\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i in range(len(axes)):\n",
    "        axes[i].imshow(images[i])        \n",
    "        axes[i].set_xticks(())\n",
    "        axes[i].set_yticks(())\n",
    "        \n",
    "        class_index = labels[i]\n",
    "        title = class_names[class_index]\n",
    "        axes[i].set_title(title, fontdict={'family':'monospace'}, loc='left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "reshaped_batch5 = reshape_cifar_img_data(cifar_data[4]['data'])\n",
    "# print(reshaped_batch5[0])\n",
    "plotImages_categories(images=reshaped_batch5, labels=cifar_data[4]['labels'], n_rows=5, n_cols=5, figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to make directories and write images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = DATA_DIR +'Cifar10_images'\n",
    "im_format = '.png'  # '.tif'\n",
    "\n",
    "CHECKPOINT_DIR = DATA_DIR +'checkpoints'\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories(images_dir,split):\n",
    "    for dir_name in class_names:\n",
    "        dir_full_path = os.path.join(images_dir+'/'+split,dir_name)\n",
    "        if not os.path.exists(dir_full_path):\n",
    "            os.makedirs(dir_full_path)\n",
    "\n",
    "def write_images_to_split_directory(batch,split,path,write_data=False,class_counter=None):\n",
    "    if class_counter is None:\n",
    "        class_counter=np.zeros(nb_classes,dtype=int)\n",
    "\n",
    "    if write_data:\n",
    "        make_directories(path,split=split)\n",
    "    images,labels = reshape_cifar_img_data(batch['data']), batch['labels']\n",
    "    filenames = batch['filenames']\n",
    "    n_images = images.shape[0]       # number of images: one data tuple per image\n",
    "    assert n_images==len(labels)     # each image has a class label\n",
    "    assert n_images==len(filenames)  # each image has a filename\n",
    "    for i in range(n_images):\n",
    "        class_index = labels[i]\n",
    "        class_  = class_names[class_index]\n",
    "        destination_dir = os.path.join(path,split,class_)\n",
    "        filename = Path(filenames[i]).stem\n",
    "        outputname = f\"{class_counter[class_index]:04d}_{filename}{im_format}\"\n",
    "        # if i % 200 == 0:\n",
    "        #     print(destination_dir, outputname)\n",
    "        if write_data:\n",
    "            imageio.imwrite(destination_dir+'/'+outputname, images[i], im_format)\n",
    "        class_counter[class_index] +=1 \n",
    "        \n",
    "    print('classnames',class_names)\n",
    "    print('images/class = ',class_counter)\n",
    "    return class_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counter=np.zeros(nb_classes,dtype=int)\n",
    "WRITE_DATA = True\n",
    "\n",
    "def export_cifar10_to_image_dirs(train_data, test_data, data_dir=IMAGES_DIR,\n",
    "                                 class_counter=None, write_data=WRITE_DATA):\n",
    "    split = 'train'\n",
    "    for batch in train_data:\n",
    "        # train_labels = batch['labels'] #np.ravel(y_train)\n",
    "\n",
    "        print(f\"\\nWriting {batch['batch_label']}: {len(batch['labels'])} images to {data_dir}/{split}\")\n",
    "\n",
    "        class_counter = write_images_to_split_directory(batch, split=split, path=data_dir,\n",
    "                                        write_data=write_data, class_counter=class_counter)        \n",
    "\n",
    "    split = 'test'\n",
    "    print(f\"\\nWriting {test_data['batch_label']}: {len(test_data['labels'])} images to '{split}'\")\n",
    "    test_counter = write_images_to_split_directory(test_data, split=split, path=IMAGES_DIR,\n",
    "                                        write_data=write_data, class_counter=None)        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cifar10_to_image_dirs(cifar_data, test_batch, data_dir=IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results visually\n",
    "sample_idx = 7 # 0, 1, 3, 4, 6, 7  (assumption: first image in a given class) \n",
    "sample_class = cifar_data[0]['labels'][sample_idx]\n",
    "sample_origdata = cifar_data[0]['data'][sample_idx]\n",
    "print(class_names[sample_class])\n",
    "filepattern = f\"{IMAGES_DIR}/train/{class_names[sample_class]}/0000_*{im_format}\"\n",
    "print(filepattern)\n",
    "sample_file = glob.glob(filepattern)[0]\n",
    "print(sample_file)\n",
    "\n",
    "\n",
    "#sample  = imageio.imread('data/Cifar10_images/train/frog/0000'+im_format)\n",
    "sample  = imageio.v2.imread(sample_file)\n",
    "print(sample.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sample)\n",
    "# reshaped_sample = reshape_imgdata(sample)\n",
    "# print(reshaped_sample.shape)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "print(sample_origdata.shape)\n",
    "sample_img = reshape_cifar_img(sample_origdata)\n",
    "plt.imshow(sample_img)\n",
    "plt.show()\n",
    "\n",
    "# Check results numerically\n",
    "print('sample min & max:',sample.min(),sample.max())\n",
    "print('source min & max:',sample_origdata.min(),sample_origdata.max())\n",
    "print('\\nsample patch:\\n',sample[0:5,0:5,1])\n",
    "print('source patch:\\n',sample_img[0:5,0:5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data_(data_path, split, class_labels=None):\n",
    "    class_counter = None\n",
    "    class_names = []\n",
    "    # for dir_name in class_names:\n",
    "    dir_full_path = os.path.join(data_path+'/'+split)\n",
    "    if not os.path.exists(dir_full_path):\n",
    "        assert False, \"Path does not exist: \"+dir_full_path\n",
    "    img_dirs = sorted([f for f in Path(dir_full_path).iterdir() if f.is_dir()])\n",
    "    class_labels = [f.name for f in img_dirs]\n",
    "    print(\"class_labels (from directory names):\", class_labels)\n",
    "    nb_classes = len(class_labels)\n",
    "    if nb_classes > 0:\n",
    "        class_counter=np.zeros(nb_classes,dtype=int)\n",
    "\n",
    "    img_tensors = []\n",
    "    for iclass, imgdir in enumerate(img_dirs):\n",
    "        img_files = sorted(imgdir.glob('*'+im_format)) # list all images \n",
    "        img_file_names = list(map(lambda f: f.stem, img_files)) # list all images \n",
    "        print(img_file_names[0:5])\n",
    "        # imgrecs = [reshape_imgdata(imageio.v2.imread(f), flatten=0) for f in img_files]\n",
    "        imgrecs = [imageio.v2.imread(f) for f in img_files]\n",
    "        npdata = np.stack(imgrecs)  # one row per image\n",
    "        assert npdata.shape[0] == len(imgrecs) # by def of np.stack()\n",
    "        print(npdata.shape)\n",
    "        class_counter[iclass] = len(imgrecs)\n",
    "        img_tensors.append(npdata)  # python list of 2D nparray: num_recs x flattened_img_data\n",
    "        # (one list entry per class label)\n",
    "        \n",
    "    print()\n",
    "    print('classnames',class_labels)\n",
    "    print('images/class = ',class_counter)\n",
    "    return img_tensors, class_labels, class_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGES_DIR   # (just checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, _labels, class_counts = read_image_data_(IMAGES_DIR, 'train', class_labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, _labels, class_counts = read_image_data_(IMAGES_DIR, 'test', class_labels=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transform_to_normalized_tensors=v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.4915, 0.4823, 0.4468),\n",
    "                         std=(0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10x = datasets.CIFAR10(\n",
    "#     data_path, train=True, download=False, transform=transform_to_normalized_tensors\n",
    "# )\n",
    "\n",
    "# cifar10x_val = datasets.CIFAR10(\n",
    "#     data_path, train=False, download=False,\n",
    "#     transform=transform_to_normalized_tensors\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cifar_data(cifar_data, label_map=None, class_names=class_names):\n",
    "    if label_map is None:\n",
    "        label_map = {0:0, 1:1}\n",
    "    _cifar_data_ = []\n",
    "    counts = {}\n",
    "    for i, cifar10_class_idx in label_map.items():\n",
    "        class_name = class_names[cifar10_class_idx]\n",
    "        counts[class_name] = 0\n",
    "        # print(class_name)\n",
    "        for img in cifar_data[cifar10_class_idx]:\n",
    "            _cifar_data_.append((transform_to_normalized_tensors(img),i))\n",
    "            counts[class_name] += 1\n",
    "\n",
    "    # print(len(_cifar_data_), _cifar_data_[0][0].shape, _cifar_data_[0][0].dtype)\n",
    "    print(counts)\n",
    "    return _cifar_data_\n",
    "\n",
    "def load_val_data(label_map=None, class_names=class_names):\n",
    "    return filter_cifar_data(validation_data, label_map=label_map, class_names=class_names)\n",
    "\n",
    "cifar2 = filter_cifar_data(training_data, label_map={0: 0, 1: 2})  # airplane, bird\n",
    "cifar2_val = filter_cifar_data(validation_data, label_map={0: 0, 1: 2})  # airplane, bird\n",
    "\n",
    "print(len(cifar2), cifar2[0][0].shape, cifar2[0][0].dtype)\n",
    "print(len(cifar2_val), cifar2_val[0][0].shape, cifar2_val[0][0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1,32*32*3)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc0 = nn.Linear(32*32*3, 512)\n",
    "        self.fc1 = nn.Linear(512, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1,32*32*3)\n",
    "        out = F.gelu(self.fc0(out))\n",
    "        out = F.gelu(self.fc1(out))\n",
    "        out = F.log_softmax(self.fc2(out), dim=1)\n",
    "        return out\n",
    "    \n",
    "model2 = Net2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        # self.conv1 = nn.Conv2d(C, C2, kernel_size=3, padding=1)  # IN_CHANNELS(C=3),W=32,H=32 -> OUT(=C2),W,H\n",
    "        # self.conv2 = nn.Conv2d(C2, C3, kernel_size=3, padding=1) # C2,W2,H2 -> C3,W2,H2\n",
    "        # self.fc1 = nn.Linear(W3xH3xC3, 32)\n",
    "        self.fc1 = nn.Linear(32*32*3, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # out = F.max_pool2d(F.gelu(self.conv1(x)), 2)     # C=3,W=32,H=32 -> C2,W2,H2\n",
    "        # out = F.max_pool2d(F.gelu(self.conv2(out)), 2)   # C2,W2,H2 -> C3,W3,H3\n",
    "        # out = out.view(-1, W3*H3*C3)\n",
    "        out = x.view(-1,3*32*32)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(F.gelu(out))\n",
    "        out = self.softmax(out)  # equivalent: F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "model3 = Net3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders for training and validation datasets\n",
    "Read about DataLoaders here:\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, val_loader, which=\"Validation\"):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "            \n",
    "    print(f\"{which} Accuracy (correct: {correct} / total: {total}) = {correct/total}\" )\n",
    "    accuracy = correct/total\n",
    "    return accuracy, correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " ### Negative Log-Likelihood, CrossEntropy (loss functions for classification)\n",
    "Can read more here:\n",
    "https://towardsdatascience.com/cross-entropy-negative-log-likelihood-and-all-that-jazz-47a95bd2e81 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()  # Works with unnormalized logits\n",
    "loss_fn = nn.NLLLoss()  # Negative Log Likelihood, assumes model outputs log probabilities (e.g. from LogSoftmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "WEIGHT_DECAY = 0.002  # (L2 regularization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, checkpoint_dir, chkpt_filename):\n",
    "    torch.save(model.state_dict(), Path(checkpoint_dir) / chkpt_filename)\n",
    "\n",
    "def load_from_checkpoint(model, checkpoint_dir, chkpt_filename):\n",
    "    model.load_state_dict(torch.load(Path(checkpoint_dir) / chkpt_filename))\n",
    "    return model\n",
    "    \n",
    "def train_model(model, data_loader,\n",
    "                n_epochs=NUM_EPOCHS,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                loss_fn=loss_fn,\n",
    "                val_loader=None,\n",
    "                model_name=None\n",
    "               ):\n",
    "    if model_name is None:\n",
    "        model_name = type(model).__name__\n",
    "    n_batches = len(data_loader)\n",
    "    best_validation_accuracy = 0.0\n",
    "    print(f\"----- Training model {model_name} {model} #params={sum(p.numel() for p in model.parameters())} with batches/epoch={n_batches}\")\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # for epoch in range(1, n_epochs+1):   # starting from 1 to NUM_EPOCHS , inclusive\n",
    "    for epoch in range(n_epochs+1):   # starting from 0 to NUM_EPOCHS , inclusive\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in data_loader:\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "                    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        # print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Epoch: {epoch}, Training loss {loss_train/n_batches :0.6f}')\n",
    "        if val_loader is not None and epoch % 5 == 0:\n",
    "            train_accuracy, _, _ = eval_accuracy(model, train_loader, which=\"Training\")\n",
    "            accuracy, _, _ = eval_accuracy(model, val_loader, which=\"Validation\")\n",
    "            # print(f\"Train accuracy: {train_accuracy}, Validation accuracy: {accuracy}\")\n",
    "            if accuracy > best_validation_accuracy:\n",
    "                print(f\"+++++ New best validation accuracy {accuracy:0.3f} at epoch {epoch}\")\n",
    "                best_validation_accuracy = accuracy\n",
    "                save_checkpoint(model, CHECKPOINT_DIR, f\"{model_name}_best.pt\")\n",
    "\n",
    "    # save the model after training\n",
    "    save_checkpoint(model, CHECKPOINT_DIR, f\"{model_name}_checkpoint_{epoch}.pt\")\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)   # specify explicit seed for random number generators, for reproducible results\n",
    "model = Net()\n",
    "# rebuild training dataloader (for reproducibility using our explicit random seed)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "train_model(model, train_loader, n_epochs=NUM_EPOCHS, learning_rate=1e-2, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "#train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "\n",
    "eval_accuracy(model, train_loader, \"Training\")\n",
    "eval_accuracy(model, val_loader, \"Validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_best = Net()\n",
    "load_from_checkpoint(model1_best, CHECKPOINT_DIR, \"Net_best.pt\")\n",
    "\n",
    "eval_accuracy(model1_best, train_loader, \"TRAINING\")\n",
    "eval_accuracy(model1_best, val_loader, \"VALIDATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)   # specify explicit seed for random number generators, for reproducible results\n",
    "model2 = Net2()\n",
    "# rebuild training dataloader (for reproducibility using our explicit random seed)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "train_model(model2, train_loader, n_epochs=NUM_EPOCHS, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_best = Net2()\n",
    "load_from_checkpoint(model2_best, CHECKPOINT_DIR, \"Net2_best.pt\")\n",
    "\n",
    "eval_accuracy(model2_best, train_loader, \"TRAINING\")\n",
    "eval_accuracy(model2_best, val_loader, \"VALIDATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model2, train_loader, \"TRAINING\")\n",
    "eval_accuracy(model2, val_loader, \"VALIDATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 2, 1: 0}\n",
    "cifar2_valSWAPPED = load_val_data(label_map=label_map)\n",
    "eval_accuracy(model2, torch.utils.data.DataLoader(cifar2_valSWAPPED, batch_size=64, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)   # specify an explicit seed for random number generators, for reproducible results\n",
    "model3 = Net3()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "train_model(model3, train_loader, n_epochs=NUM_EPOCHS, val_loader=val_loader)\n",
    "print(\"-----TRAINING FINISHED-----\")\n",
    "eval_accuracy(model3, train_loader, \"TRAINING\")\n",
    "eval_accuracy(model3, val_loader, \"VALIDATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_best = Net3()\n",
    "load_from_checkpoint(model3_best, CHECKPOINT_DIR, \"Net3_best.pt\")\n",
    "\n",
    "eval_accuracy(model3_best, train_loader, \"TRAINING\")\n",
    "eval_accuracy(model3_best, val_loader, \"VALIDATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {1: 2}\n",
    "cifar2_valBird = load_val_data(label_map=label_map)\n",
    "val_loader_alt = torch.utils.data.DataLoader(cifar2_valBird, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model3_best, val_loader_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0}\n",
    "cifar2_valAirplane = load_val_data(label_map=label_map)\n",
    "val_loader_alt = torch.utils.data.DataLoader(cifar2_valAirplane, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model3_best, val_loader_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 1: 5}\n",
    "cifar2_valAirplaneDog = load_val_data(label_map=label_map)\n",
    "val_loader_alt = torch.utils.data.DataLoader(cifar2_valAirplaneDog, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model3_best, val_loader_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 5, 1: 2}\n",
    "cifar2_valDogBird = load_val_data(label_map=label_map)\n",
    "val_loader_alt = torch.utils.data.DataLoader(cifar2_valDogBird, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model3_best, val_loader_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 5} \n",
    "cifar2_valDog0 = load_val_data(label_map=label_map)\n",
    "val_loader_alt = torch.utils.data.DataLoader(cifar2_valDog0, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model3_best, val_loader_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {1: 5} \n",
    "cifar2_valDog1 = load_val_data(label_map=label_map)\n",
    "val_loader_alt = torch.utils.data.DataLoader(cifar2_valDog1, batch_size=64, shuffle=False)\n",
    "eval_accuracy(model3_best, val_loader_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
